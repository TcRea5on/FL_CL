{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimport argparse\n",
    "\n",
    "def args_parser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # federated arguments\n",
    "    parser.add_argument('--epochs', type=int, default=500, help=\"rounds of training\")\n",
    "    parser.add_argument('--num_users', type=int, default=100, help=\"number of users: K\")\n",
    "    parser.add_argument('--frac', type=float, default=0.1, help=\"the fraction of clients: C\")\n",
    "    parser.add_argument('--local_ep', type=int, default=5, help=\"the number of local epochs: E\")\n",
    "    parser.add_argument('--local_bs', type=int, default=10, help=\"local batch size: B\")\n",
    "    parser.add_argument('--bs', type=int, default=128, help=\"test batch size\")\n",
    "    parser.add_argument('--lr', type=float, default=0.001, help=\"learning rate (default: 0.01)\")\n",
    "    parser.add_argument('--lr_decay', type=float, default=0.95, help=\"lr decay\")\n",
    "    parser.add_argument('--momentum', type=float, default=0.5, help=\"SGD momentum (default: 0.5)\")\n",
    "    parser.add_argument('--split', type=str, default='user', help=\"train-test split type, user or sample\")\n",
    "\n",
    "    # model arguments\n",
    "    parser.add_argument('--model', type=str, default='cnn', help='model name')\n",
    "    parser.add_argument('--kernel_num', type=int, default=9, help='number of each kind of kernel')\n",
    "    parser.add_argument('--kernel_sizes', type=str, default='3,4,5',\n",
    "                        help='comma-separated kernel size to use for convolution')\n",
    "    parser.add_argument('--norm', type=str, default='batch_norm', help=\"batch_norm, layer_norm, or None\")\n",
    "    parser.add_argument('--num_filters', type=int, default=32, help=\"number of filters for conv nets\")\n",
    "    parser.add_argument('--max_pool', type=str, default='True',\n",
    "                        help=\"Whether use max pooling rather than strided convolutions\")\n",
    "\n",
    "    # other arguments\n",
    "    parser.add_argument('--dataset', type=str, default='mnist', help=\"name of dataset\")\n",
    "    parser.add_argument('--iid', action='store_true', help='whether i.i.d or not')\n",
    "    parser.add_argument('--num_classes', type=int, default=10, help=\"number of classes\")\n",
    "    parser.add_argument('--num_channels', type=int, default=1, help=\"number of channels of imges\")\n",
    "    parser.add_argument('--gpu', type=int, default=-1, help=\"GPU ID, -1 for CPU\")\n",
    "    parser.add_argument('--stopping_rounds', type=int, default=10, help='rounds of early stopping')\n",
    "    parser.add_argument('--verbose', action='store_true', help='verbose print')\n",
    "    parser.add_argument('--seed', type=int, default=1, help='random seed (default: 1)')\n",
    "    parser.add_argument('--all_clients', action='store_true', help='aggregation over all clients')\n",
    "    args = parser.parse_args(args=[])\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNMnist(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Python version: 3.6\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "import random\n",
    "from torchvision import datasets, transforms\n",
    "from collections import deque\n",
    "  \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils.sampling import mnist_iid, mnist_noniid, cifar_iid\n",
    "from models.Update import LocalUpdate\n",
    "from models.Nets import MLP, CNNMnist, CNNCifar\n",
    "from models.Fed import FedAvg\n",
    "from models.test import test_img\n",
    "\n",
    "# parse args\n",
    "args = args_parser()\n",
    "args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
    "\n",
    "# load dataset and split users\n",
    "if args.dataset == 'mnist':\n",
    "    trans_mnist = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.repeat(1,1,1))])\n",
    "    dataset_train = datasets.MNIST('./data/mnist/', train=True, download=False, transform=trans_mnist)\n",
    "    dataset_test = datasets.MNIST('./data/mnist/', train=False, download=True, transform=trans_mnist)\n",
    "    # sample users\n",
    "    args.iid = False\n",
    "    if args.iid:\n",
    "        dict_users = mnist_iid(dataset_train, args.num_users)\n",
    "    else:\n",
    "        dict_users = mnist_noniid(dataset_train, args.num_users)\n",
    "elif args.dataset == 'cifar':\n",
    "    trans_cifar = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    dataset_train = datasets.CIFAR10('./data/cifar', train=True, download=True, transform=trans_cifar)\n",
    "    dataset_test = datasets.CIFAR10('./data/cifar', train=False, download=True, transform=trans_cifar)\n",
    "    if args.iid:\n",
    "        dict_users = cifar_iid(dataset_train, args.num_users)\n",
    "    else:\n",
    "        exit('Error: only consider IID setting in CIFAR10')\n",
    "else:\n",
    "    exit('Error: unrecognized dataset')\n",
    "img_size = dataset_train[0][0].shape\n",
    "\n",
    "# build model\n",
    "if args.model == 'cnn' and args.dataset == 'cifar':\n",
    "    net_glob = CNNCifar(args=args).to(args.device)\n",
    "elif args.model == 'cnn' and args.dataset == 'mnist':\n",
    "    net_glob = CNNMnist(args=args).to(args.device)\n",
    "elif args.model == 'mlp':\n",
    "    len_in = 1\n",
    "    for x in img_size:\n",
    "        len_in *= x\n",
    "    net_glob = MLP(dim_in=len_in, dim_hidden=200, dim_out=args.num_classes).to(args.device)\n",
    "else:\n",
    "    exit('Error: unrecognized model')\n",
    "print(net_glob)\n",
    "net_glob.train()\n",
    "\n",
    "# copy weights\n",
    "w_glob = net_glob.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryBuffer: # MemoryBuffer类实现的功能：buffer内采样，往buffer里塞（sars）\n",
    "\n",
    "    def __init__(self, size):\n",
    "        self.buffer = deque(maxlen=size) #buffer设置为双端队列\n",
    "        self.maxSize = size\n",
    "        self.len = 0\n",
    "        \n",
    "    def state_reco(self, s):\n",
    "        s_1 = [i[0] for i in s]\n",
    "        s_2 = [i[1] for i in s]\n",
    "        s_3 = [i[2] for i in s]\n",
    "        return [torch.cat(s_1),torch.cat(s_2),torch.cat(s_3)]\n",
    "\n",
    "    def sample(self, count):\n",
    "        \"\"\"\n",
    "        samples a random batch from the replay memory buffer\n",
    "        :param count: batch size\n",
    "        :return: batch (numpy array)\n",
    "        \"\"\"\n",
    "        batch = []\n",
    "        count = min(count, self.len)\n",
    "        batch = random.sample(self.buffer, count) # 随机取样\n",
    "\n",
    "        s_arr = [arr[0] for arr in batch]\n",
    "        a_arr = torch.cat([arr[1] for arr in batch])\n",
    "        r_arr = torch.tensor([arr[2] for arr in batch]).reshape(-1,1)\n",
    "        s1_arr = [arr[3] for arr in batch]\n",
    "\n",
    "        return self.state_reco(s_arr), a_arr, r_arr, self.state_reco(s1_arr)\n",
    "\n",
    "    def len(self):\n",
    "        return self.len\n",
    "\n",
    "    def add(self, s, a, r, s1):\n",
    "        \"\"\"\n",
    "        adds a particular transaction in the memory buffer\n",
    "        :param s: current state\n",
    "        :param a: action taken\n",
    "        :param r: reward received\n",
    "        :param s1: next state\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        transition = (s,a,r,s1)\n",
    "        self.len += 1\n",
    "        if self.len > self.maxSize:\n",
    "            self.len = self.maxSize\n",
    "        self.buffer.append(transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "\n",
    "    def __init__(self, parameter_dim, loss_dim, action_dim):\n",
    "        super(Actor, self).__init__()\n",
    "\n",
    "        self.parameter_dim = parameter_dim\n",
    "        self.loss_dim = loss_dim\n",
    "        self.action_dim = action_dim\n",
    "\n",
    "        self.fc1 = nn.Linear(parameter_dim,action_dim)\n",
    "\n",
    "        self.fc2 = nn.Linear(action_dim*12,action_dim)\n",
    "\n",
    "    def forward(self, parameters, last_loss, last_weight):\n",
    "        parameter_lst = []\n",
    "        for i in range(self.action_dim):\n",
    "            parameter_lst.append(self.fc1(parameters[:,i,:]))\n",
    "        parameter_layer = torch.cat(parameter_lst,dim=1)\n",
    "        x = torch.cat([parameter_layer,last_loss, last_weight],dim=1)\n",
    "        action = F.softmax(self.fc2(x),dim=1)\n",
    "\n",
    "        return action\n",
    "\n",
    "class Critic(nn.Module):\n",
    "\n",
    "    def __init__(self, parameter_dim, loss_dim, action_dim):\n",
    "        super(Critic, self).__init__()\n",
    "\n",
    "        self.parameter_dim = parameter_dim\n",
    "        self.loss_dim = loss_dim\n",
    "        self.action_dim = action_dim\n",
    "\n",
    "        self.fc1 = nn.Linear(parameter_dim,action_dim)\n",
    "\n",
    "        self.fc2 = nn.Linear(action_dim*13,1)\n",
    "\n",
    "    def forward(self, parameters, last_loss, last_weight, action):\n",
    "        parameter_lst = []\n",
    "        for i in range(self.action_dim):\n",
    "            parameter_lst.append(self.fc1(parameters[:,i,:]))\n",
    "        parameter_layer = torch.cat(parameter_lst,dim=1)\n",
    "        x = torch.cat([parameter_layer,last_loss, last_weight, action],dim=1)\n",
    "        q = self.fc2(x)\n",
    "\n",
    "        return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA=0.8\n",
    "class Trainer:\n",
    "\n",
    "    def __init__(self, parameter_dim, loss_dim, action_dim, replay_buffer):\n",
    "        self.parameter_dim = parameter_dim\n",
    "        self.loss_dim = loss_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.replay_buffer = replay_buffer\n",
    "        self.iter = 0\n",
    "        #self.noise = utils.OrnsteinUhlenbeckActionNoise(self.action_dim)\n",
    "\n",
    "        self.actor = Actor(self.parameter_dim, \n",
    "                                 self.loss_dim, \n",
    "                                 self.action_dim)\n",
    "        self.target_actor = Actor(self.parameter_dim, \n",
    "                                 self.loss_dim, \n",
    "                                 self.action_dim)\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(),0.01)\n",
    "\n",
    "        self.critic = Critic(self.parameter_dim, \n",
    "                                 self.loss_dim, \n",
    "                                 self.action_dim)\n",
    "        self.target_critic = Critic(self.parameter_dim, \n",
    "                                 self.loss_dim, \n",
    "                                 self.action_dim)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(),0.01)\n",
    "\n",
    "        self.hard_update(self.target_actor, self.actor)\n",
    "        self.hard_update(self.target_critic, self.critic)\n",
    "\n",
    "    def soft_update(self, target, source, tau):\n",
    "        for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "            target_param.data.copy_(\n",
    "                target_param.data * (1.0 - tau) + param.data * tau\n",
    "            )\n",
    "    def hard_update(self, target, source):\n",
    "        for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "                target_param.data.copy_(param.data)\n",
    "                \n",
    "    def get_exploitation_action(self, parameters, last_loss, last_weight):\n",
    "        action = self.target_actor.forward(parameters, last_loss, last_weight).detach()\n",
    "        return action.data.numpy()\n",
    "\n",
    "#     def get_exploration_action(self, state):\n",
    "#         \"\"\"\n",
    "#         gets the action from actor added with exploration noise\n",
    "#         :param state: state (Numpy array)\n",
    "#         :return: sampled action (Numpy array)\n",
    "#         \"\"\"\n",
    "#         state = Variable(torch.from_numpy(state))\n",
    "#         action = self.actor.forward(state).detach()\n",
    "#         new_action = action.data.numpy() + (self.noise.sample())\n",
    "#         return new_action\n",
    "\n",
    "    def optimize(self):\n",
    "        \"\"\"\n",
    "        Samples a random batch from replay memory and performs optimization\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        s1,a1,r1,s2 = self.replay_buffer.sample(8)\n",
    "\n",
    "#         s1 = Variable(torch.from_numpy(s1))\n",
    "#         a1 = Variable(torch.from_numpy(a1))\n",
    "#         r1 = Variable(torch.from_numpy(r1))\n",
    "#         s2 = Variable(torch.from_numpy(s2))\n",
    "\n",
    "        # ---------------------- optimize critic ----------------------\n",
    "        # Use target actor exploitation policy here for loss evaluation\n",
    "        # 这里应该是TD的方法\n",
    "        a2 = self.target_actor.forward(s2[0],s2[1],s2[2]).detach()\n",
    "        next_val = torch.squeeze(self.target_critic.forward(s2[0],s2[1],s2[2], a2).detach())\n",
    "        # y_exp = r + gamma*Q'( s2, pi'(s2))\n",
    "        y_expected = r1 + GAMMA*next_val\n",
    "        # y_pred = Q( s1, a1)\n",
    "        y_predicted = torch.squeeze(self.critic.forward(s1[0],s1[1],s1[2], a1))\n",
    "        # compute critic loss, and update the critic\n",
    "        loss_critic = F.smooth_l1_loss(y_predicted, y_expected)\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        loss_critic.backward(retain_graph=True)\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "        # ---------------------- optimize actor ----------------------\n",
    "        pred_a1 = self.actor.forward(s1[0],s1[1],s1[2])\n",
    "        loss_actor = -1*torch.sum(self.critic.forward(s1[0],s1[1],s1[2], pred_a1))\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        loss_actor.backward(retain_graph=True)\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        self.soft_update(self.target_actor, self.actor, 0.001)\n",
    "        self.soft_update(self.target_critic, self.critic, 0.001)\n",
    "\n",
    "        # if self.iter % 100 == 0:\n",
    "        #     print 'Iteration :- ', self.iter, ' Loss_actor :- ', loss_actor.data.numpy(),\\\n",
    "        #         ' Loss_critic :- ', loss_critic.data.numpy()\n",
    "        # self.iter += 1\n",
    "\n",
    "    def save_models(self, episode_count):\n",
    "        torch.save(self.target_actor.state_dict(), './Models/' + str(episode_count) + '_actor.pt')\n",
    "        torch.save(self.target_critic.state_dict(), './Models/' + str(episode_count) + '_critic.pt')\n",
    "        \n",
    "    def load_models(self, episode):\n",
    "        self.actor.load_state_dict(torch.load('./Models/' + str(episode) + '_actor.pt'))\n",
    "        self.critic.load_state_dict(torch.load('./Models/' + str(episode) + '_critic.pt'))\n",
    "        utils.hard_update(self.target_actor, self.actor)\n",
    "        utils.hard_update(self.target_critic, self.critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramter = []\n",
    "for i in w_glob.keys():\n",
    "    paramter.append(w_glob[i].reshape(1,-1))\n",
    "\n",
    "parameter_dim = torch.cat(paramter,axis=1).shape[1]\n",
    "loss_dim = max(int(args.frac * args.num_users), 1)\n",
    "action_dim = max(int(args.frac * args.num_users), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = MemoryBuffer(500)\n",
    "trainer = Trainer(parameter_dim, loss_dim, action_dim, replay_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FedPareto(w,action):\n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    for k in w_avg.keys():\n",
    "        for i in range(0, len(w)):\n",
    "            if i==0:\n",
    "                w_avg[k] = action[i] * w[i][k]\n",
    "            else:\n",
    "                w_avg[k] += action[i] * w[i][k]\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   0, Average loss 1.743\n",
      "Round   1, Average loss 1.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:77: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   2, Average loss 0.918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:77: UserWarning: Using a target size (torch.Size([2, 2])) that is different to the input size (torch.Size([2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   3, Average loss 0.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:77: UserWarning: Using a target size (torch.Size([3, 3])) that is different to the input size (torch.Size([3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   4, Average loss 0.619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:77: UserWarning: Using a target size (torch.Size([4, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   5, Average loss 0.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:77: UserWarning: Using a target size (torch.Size([5, 5])) that is different to the input size (torch.Size([5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   6, Average loss 0.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:77: UserWarning: Using a target size (torch.Size([6, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   7, Average loss 0.420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:77: UserWarning: Using a target size (torch.Size([7, 7])) that is different to the input size (torch.Size([7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   8, Average loss 0.362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:77: UserWarning: Using a target size (torch.Size([8, 8])) that is different to the input size (torch.Size([8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   9, Average loss 0.269\n",
      "Round  10, Average loss 0.359\n",
      "Round  11, Average loss 0.336\n",
      "Round  12, Average loss 0.310\n",
      "Round  13, Average loss 0.329\n",
      "Round  14, Average loss 0.264\n",
      "Round  15, Average loss 0.341\n",
      "Round  16, Average loss 0.294\n",
      "Round  17, Average loss 0.302\n",
      "Round  18, Average loss 0.338\n",
      "Round  19, Average loss 0.266\n",
      "Round  20, Average loss 0.176\n",
      "Round  21, Average loss 0.163\n",
      "Round  22, Average loss 0.230\n",
      "Round  23, Average loss 0.278\n",
      "Round  24, Average loss 0.172\n",
      "Round  25, Average loss 0.284\n",
      "Round  26, Average loss 0.212\n",
      "Round  27, Average loss 0.238\n",
      "Round  28, Average loss 0.248\n",
      "Round  29, Average loss 0.260\n",
      "Round  30, Average loss 0.179\n",
      "Round  31, Average loss 0.188\n",
      "Round  32, Average loss 0.204\n",
      "Round  33, Average loss 0.139\n",
      "Round  34, Average loss 0.217\n",
      "Round  35, Average loss 0.198\n",
      "Round  36, Average loss 0.206\n",
      "Round  37, Average loss 0.174\n",
      "Round  38, Average loss 0.189\n",
      "Round  39, Average loss 0.149\n",
      "Round  40, Average loss 0.146\n",
      "Round  41, Average loss 0.167\n",
      "Round  42, Average loss 0.223\n",
      "Round  43, Average loss 0.170\n",
      "Round  44, Average loss 0.127\n",
      "Round  45, Average loss 0.129\n",
      "Round  46, Average loss 0.174\n",
      "Round  47, Average loss 0.169\n",
      "Round  48, Average loss 0.161\n",
      "Round  49, Average loss 0.185\n",
      "Round  50, Average loss 0.149\n",
      "Round  51, Average loss 0.176\n",
      "Round  52, Average loss 0.168\n",
      "Round  53, Average loss 0.224\n",
      "Round  54, Average loss 0.154\n",
      "Round  55, Average loss 0.187\n",
      "Round  56, Average loss 0.149\n",
      "Round  57, Average loss 0.156\n",
      "Round  58, Average loss 0.134\n",
      "Round  59, Average loss 0.185\n",
      "Round  60, Average loss 0.158\n",
      "Round  61, Average loss 0.142\n",
      "Round  62, Average loss 0.148\n",
      "Round  63, Average loss 0.136\n",
      "Round  64, Average loss 0.156\n",
      "Round  65, Average loss 0.120\n",
      "Round  66, Average loss 0.155\n",
      "Round  67, Average loss 0.122\n",
      "Round  68, Average loss 0.219\n",
      "Round  69, Average loss 0.151\n",
      "Round  70, Average loss 0.225\n",
      "Round  71, Average loss 0.177\n",
      "Round  72, Average loss 0.141\n",
      "Round  73, Average loss 0.153\n",
      "Round  74, Average loss 0.154\n",
      "Round  75, Average loss 0.164\n",
      "Round  76, Average loss 0.146\n",
      "Round  77, Average loss 0.125\n",
      "Round  78, Average loss 0.162\n",
      "Round  79, Average loss 0.162\n",
      "Round  80, Average loss 0.148\n",
      "Round  81, Average loss 0.180\n",
      "Round  82, Average loss 0.166\n",
      "Round  83, Average loss 0.163\n",
      "Round  84, Average loss 0.187\n",
      "Round  85, Average loss 0.114\n",
      "Round  86, Average loss 0.163\n",
      "Round  87, Average loss 0.155\n",
      "Round  88, Average loss 0.165\n",
      "Round  89, Average loss 0.178\n",
      "Round  90, Average loss 0.231\n",
      "Round  91, Average loss 0.163\n",
      "Round  92, Average loss 0.173\n",
      "Round  93, Average loss 0.173\n",
      "Round  94, Average loss 0.160\n",
      "Round  95, Average loss 0.177\n",
      "Round  96, Average loss 0.114\n",
      "Round  97, Average loss 0.175\n",
      "Round  98, Average loss 0.143\n",
      "Round  99, Average loss 0.156\n",
      "Round 100, Average loss 0.139\n",
      "Round 101, Average loss 0.146\n",
      "Round 102, Average loss 0.210\n",
      "Round 103, Average loss 0.159\n",
      "Round 104, Average loss 0.164\n",
      "Round 105, Average loss 0.219\n",
      "Round 106, Average loss 0.187\n",
      "Round 107, Average loss 0.183\n",
      "Round 108, Average loss 0.191\n",
      "Round 109, Average loss 0.167\n",
      "Round 110, Average loss 0.212\n",
      "Round 111, Average loss 0.190\n",
      "Round 112, Average loss 0.165\n",
      "Round 113, Average loss 0.216\n",
      "Round 114, Average loss 0.140\n",
      "Round 115, Average loss 0.206\n",
      "Round 116, Average loss 0.198\n",
      "Round 117, Average loss 0.192\n",
      "Round 118, Average loss 0.173\n",
      "Round 119, Average loss 0.181\n",
      "Round 120, Average loss 0.227\n",
      "Round 121, Average loss 0.179\n",
      "Round 122, Average loss 0.150\n",
      "Round 123, Average loss 0.205\n",
      "Round 124, Average loss 0.159\n",
      "Round 125, Average loss 0.175\n",
      "Round 126, Average loss 0.179\n",
      "Round 127, Average loss 0.190\n",
      "Round 128, Average loss 0.133\n",
      "Round 129, Average loss 0.192\n",
      "Round 130, Average loss 0.171\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-74-05d9a84a9dc7>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     25\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0midxs_users\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m         \u001B[0mlocal\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mLocalUpdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdataset_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0midxs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdict_users\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 27\u001B[0;31m         \u001B[0mw\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlocal\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnet\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdeepcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnet_glob\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     28\u001B[0m         \u001B[0;31m############ 储存参数 ##############\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m         \u001B[0mp_local\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/home/chenweilong/federated-learning-cp/models/Update.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, net)\u001B[0m\n\u001B[1;32m     44\u001B[0m                 \u001B[0mlog_probs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnet\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     45\u001B[0m                 \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloss_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlog_probs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 46\u001B[0;31m                 \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     47\u001B[0m                 \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mverbose\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mbatch_idx\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;36m10\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph)\u001B[0m\n\u001B[1;32m    193\u001B[0m                 \u001B[0mproducts\u001B[0m\u001B[0;34m.\u001B[0m \u001B[0mDefaults\u001B[0m \u001B[0mto\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    194\u001B[0m         \"\"\"\n\u001B[0;32m--> 195\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    196\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    197\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001B[0m\n\u001B[1;32m     97\u001B[0m     Variable._execution_engine.run_backward(\n\u001B[1;32m     98\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 99\u001B[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001B[0m\u001B[1;32m    100\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "loss_train = []\n",
    "cv_loss, cv_acc = [], []\n",
    "val_loss_pre, counter = 0, 0\n",
    "net_best = None\n",
    "best_loss = None\n",
    "val_acc_list, net_list = [], []\n",
    "\n",
    "loss_save = []\n",
    "\n",
    "last_replay_data = []\n",
    "for iter in range(args.epochs):\n",
    "    if iter==0:\n",
    "        random_n = 0\n",
    "        n_weight = []\n",
    "        while random_n<10:\n",
    "            n_weight.append(random.random()) # 随机初始化参数\n",
    "            random_n+=1\n",
    "        action = F.softmax(torch.tensor(n_weight))\n",
    "    loss_locals = []\n",
    "    w_locals = []\n",
    "    m = max(int(args.frac * args.num_users), 1)\n",
    "    idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "    p_collect = []\n",
    "    for idx in idxs_users:\n",
    "        local = LocalUpdate(args=args, dataset=dataset_train, idxs=dict_users[idx])\n",
    "        w, loss = local.train(net=copy.deepcopy(net_glob).to(args.device))\n",
    "        ############ 储存参数 ##############\n",
    "        p_local = []\n",
    "        for i in w.keys():\n",
    "            p_local.append(w[i].reshape(1,-1))\n",
    "        p_collect.append(torch.cat(p_local,axis=1))\n",
    "        ############ 储存loss ##############\n",
    "        w_locals.append(copy.deepcopy(w))\n",
    "        loss_locals.append(copy.deepcopy(loss))\n",
    "    p_collect = torch.cat(p_collect).unsqueeze(0)\n",
    "    action_next = trainer.target_actor.forward(p_collect,\n",
    "                                          torch.tensor(loss_locals).reshape(1,-1), \n",
    "                                          action.reshape(1,-1))[0]\n",
    "    ###########计算当前轮的reward，然后将当前轮的reward添加到上一个replay_data中\n",
    "    reward = -sum(loss_locals) / len(loss_locals)\n",
    "    loss_save.append(reward)\n",
    "    if len(last_replay_data)==2:\n",
    "        last_replay_data.append(reward)#r\n",
    "        last_replay_data.append([p_collect, \n",
    "                                 torch.tensor(loss_locals).reshape(1,-1), \n",
    "                                 action.reshape(1,-1)])#s_next\n",
    "        trainer.replay_buffer.add(last_replay_data[0],\n",
    "                                  last_replay_data[1],\n",
    "                                  last_replay_data[2],\n",
    "                                  last_replay_data[3])\n",
    "    last_replay_data = [[p_collect, \n",
    "                         torch.tensor(loss_locals).reshape(1,-1), \n",
    "                         action.reshape(1,-1)], \n",
    "                        action_next.reshape(1,-1)]#s, a\n",
    "    action = action_next\n",
    "    # update global weights\n",
    "    # w_glob = FedAvg(w_locals)\n",
    "    w_glob = FedPareto(w_locals, action_next)\n",
    "\n",
    "    # copy weight to net_glob\n",
    "    net_glob.load_state_dict(w_glob)\n",
    "\n",
    "    # print loss\n",
    "    print('Round {:3d}, Average loss {:.3f}'.format(iter, -reward))\n",
    "    loss_train.append(-reward)\n",
    "    \n",
    "    if iter > 0:\n",
    "        trainer.optimize()\n",
    "    args.lr = max(args.lr*args.lr_decay, 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 56.29\n",
      "Testing accuracy: 56.48\n"
     ]
    }
   ],
   "source": [
    "# plot loss curve\n",
    "# plt.figure()\n",
    "# plt.plot(range(len(loss_train)), loss_train)\n",
    "# plt.ylabel('train_loss')\n",
    "# plt.show()\n",
    "# plt.savefig('./save/fed_{}_{}_{}_C{}_iid{}.png'.format(args.dataset, args.model, args.epochs, args.frac, args.iid))\n",
    "\n",
    "# testing\n",
    "net_glob.eval()\n",
    "acc_train, loss_train = test_img(net_glob, dataset_train, args)\n",
    "acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "print(\"Training accuracy: {:.2f}\".format(acc_train))\n",
    "print(\"Testing accuracy: {:.2f}\".format(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1f3/8dcnyyRkITshISwJ+w4SWWRxAxVUUFtaqlVsi2hrW+u3tV+t7Vf9/rrot61Va6tSrLXuS0FQUTZB9iXsS4CEsGUhJCEbhGQyM+f3x0yGhKwwCQkzn+fjkQczd87MOblk3nPm3HPPFWMMSimlvJ9fezdAKaXU5aGBr5RSPkIDXymlfIQGvlJK+QgNfKWU8hEB7d2ApsTGxppevXq1dzOUUuqKsW3btkJjTFxDj3XowO/VqxdpaWnt3QyllLpiiMixxh7TIR2llPIRGvhKKeUjNPCVUspHaOArpZSP0MBXSikfoYGvlFI+QgNfKaV8hAa+Uj5k6b6THCs626Z1OByGz3bnYrU52rQedfE08JW6SO9tOc7CHdnu+8YYPtmRQ0mFtU3qs9kdnLPaPX6d0nPV/PDtbTy9eF8rtKpxqw+d4sfv7uCjbSfatB518TTw1WVjdxhmvrqBCc99xcxXN/CPNVnt0g6H49Iv+nO44Ay//mQv//2fPWQXVwCweFcuP/tgJ+9uOd5aTXQrPVfNjL+tZ8bf1mGze9Zj3pRVhMPA14cKyC0510otrG/5/lMALN2X32Z1eJMKq+2y1aWBrwDIPFXO3pzSNq1j+f6TbD1aTO+4MMorbfxuSTqZp860aZ0XWnOogKt+u5x1GYUNPl5ZbafmKnA2u4N/rT/CT9/bQWlFNQDPLztEUIAfAvxp6UEqrDb+sOQAwEXtv/LK6mbLVFbbeeDNNPbnlXEo/wz/2Z7d7HOasj6zEEuAHw4DH2/z7LUa43AYVqbnIwIbDxdS1sTvuS+3lLSjp2nPq+7tzSmlstrzb0+XanNWEcOeXtbm770aGvgKgJ9/tJuH3t520c+rstlZm1HAq18f5v++POAOxobMX3uEHtEh/PP+q3l7zhgs/n78e+PRFtVTUmGl+hJ6uCUVVkrPOdu0N6eUH769jZKKat5Yf6Re2bc2HWPwU0u55tmv+PUne7j1pXU8/el+Fu/KZfYbW9hwuJDP9+QxZ2IKP5iQzCc7c3n0g52cLKskJS6U3dkte9O+tekYw55ZxhML9lB0pqrBMlabgx+/u4Otx07zwrdHMLx7JC+uyKDKVjecckvOcbigZR+a6zMLuaZ3DOP7xPDB1hMefdNpzJ6cUk6VV3HPmB5U2w2rDjh7+x9uPcH0l9exPrMQYwzz12Zx21/X8c1XNzLpj6t4c8PRVm9Lc/LLKpnxt/XMa6Vvmhf+37TEx9uysTmcQ4KXgwa+oqC8il0nSsguPucepmipR97byb2vb+HZLw7wyteHeeCttAZ7TDuOF5N2rJjvje+Fv58QGxbE7cMT+XhbdpO9QICyymomP7+G+17fgr2JkNp+vJjnlx9y9xirbHZu++s6Rv2/5cz+5xbuf2MrkSEWvjkqidWHCjhVXgk4e6W/X5LObz7ZyzW9YxjaLYKPt2Vz1mrjtXtH8Y/7UtmbU8q9r28hOtTCAxOTeei63kSHWli6L587RiQyc1R3sovPUXzWOY6/NqOAW15Yw5mqul/XyyqreX7ZQRIjOvFh2gmu/9Nq7n19Mw+/s51XVh/mbJWNymo7c99KY0V6Ps9MH8yMEd147Kb+5JZW8u5m57CRMYb3txxn8vNfc8fL692/S2PySs9xuOAsE/rE8u2re5BTco71hws5UniW97Ycp6C84Q+ei7UiPR9/P+G/pvQnLjyIpftOcrK0kmc+3ce+3DLumb+Z6S+v57efp3PL4K78eeZwYsOCeGrxPo4Xnf/bM8a0ec9/4+Ei7A7DinTPh54W7shm6NPLWvzhC84P9aX7TgLwxd6Tl+WbjgZ+B2SM4Ys9eew4XnxZ6lt98JT79uas0y1+3t6cUr7cd5I5E5LZ8ZspvDhrJFuOnObRD3bWC+b5644QHhzAzNTu7m33X9OLCqudj9LODy/klZ7j+WUH+e1n+92vMe/rLArPVLExq4hXVmc22p55X2fx0soMvtjrfBN9sPUE2cXnmD4ikazCMziM4c3vX80Pr+uN3WFYuN3Zq3r2ywPMW5PFfeN68q/vjWbefansfupm1jx2PTcP7sqUQfG8MGsEAI9O7kt4cCCdgwN5YuoAkqI68fjUgQztFuHcJ7nOXv5HadkcOFnOpsNFddr46urDFFdU89q9o/jykYlc178LZ6pspOeV8dyXB7j2j6v41msb+fpQAb+/cyj3jesFwPg+MYxLieHFlRk8+FYa33hlA48v2MOQxAiqbA5+/3m6u47Simq2HDnNB1uPs9FV//rMItfrxHLToHgiQwL56Xs7uP5Pq3liwR6u/eMq/rzsYKNDTWszCticVVRv+9HCs9z/xhb+8EU6Dodh+f58UntGER1q4aZB8aw+WMD/LNpLtcPwxSMTefj63hzKL+fH1/fhb3dfxTdGJfHCt537dnmt4L339S1c/bsV/OKjXWw43PDwW0OMMY12Ckorqut8o6rZN7uzSz36wMsvq+SpRfuw2hwsqDXs9uKKDGa+uqHRTtTajALKKm3cNiyBnJJz7GrhN0RPdOjlkX1RTsk5Hv/PbtZmFNI/Ppylj06qVyar4Ax+IvSKDW2VOr86cIr4zkFU2RxsyiriG6OSGi1bfNZKVKgFgL+vziQ8KICf3NiXiE6BTB+eyKmySn77eTrz12bx4LW9AcguruCLPXk8MDGFsKDzf3JDkyJI7RnFvzYcobLazpYjp1mXWeh+w1oC/Lj/ml68vu4Itw9PBOAvKzLoFtWJLUdO89WBU7w++2qGdIvAZnew3hUMv1+Szvg+sfxtVSajk6P588zhAFTbDZYAZx9nVM8oPkw7Qb/4cOatyeK7Y3vwzPTBiIi77tpuG5bIdf271Gn/zNTufHNUEiJCcKCz/J6cUq7pHcuajAIA1h8uZPKgeMD5Yfb6uiPcMSKRIa4PiJe+M9L9etuPF/PcFwfYdqyY5781nDtHnv9/EBGevHUgj328m6OFFQT4C7++dSDfH5/MCysO8dJXmcxM7U5W4Vl+/3k651zfsvwE5s9OZX1mITGhFvrHh+PnJ8yZkMzH27L5wYRkxvWO5Z/rj/DXrzL5MO0Ez0wfwi1DurrrPme1M+fNNKpsDkYnR3PPmB6EWgLIKjzDX5Zn4DCG1QcLSM8r58DJcn5960AAbh7clXc2H2fZ/nx+Nrkv/eLDeezmAfzXlP74+4n79XvGhNIvPowV+/P5wYRkMvLLWZdZyNBuESzbd5IF27P5+rHr6R4d0ujfZU07756/iS7hQbx2b2qdx06ftXLrS2uJDLGw5KcTEBE2ZhXRKyaEo0UVrD54qk5npLbcknMUV1gZnBhR7zFjDE8u3EuVzcHAhM4s2pnLL27qT3mVjdfWHKbCamfGy+t59d5RXN0rus5zP9udR0SnQJ6ZPpil+06yZE8eI7pHsuFwIVuPFPPTG/u4/x5biwZ+B1J81sq0F9dSbXcwoU8s6zILyS05R2JkpzrlfvbBToID/fnwwXEX9fobDheSeeoMd4zsRufgQMD5tXJtRiG3D0/g9Fkrm4803sN/d/NxfrVwDw9em8KdI7vxxd6TPHxdHyI6BbrLzJmYwrL9+XyYdoK5k1IQEf6zLQcD3DuuZ73X/N74ZB5+dzt/XHqQ3nGhzJmYzHfH9OTvqw/z99WHWZdZSLXdwc+n9CM6zMKO48U8+sEuggP9sDsMH6adYEi3CHZll1JeaePuMT14d/NxZs3bRH5ZFS98e2StED//5pk5KonHF+zh4Xe3M6BrOL++dVCzb67aYV+j5jmRIRa6R3dib04pu7JLKKmoJijAjw2Z53vFL63MwBj4+U39G3z9q3pE8f7csVRY7YQ2UNeQbhF88cjEett/dH0fPtmZy/fe2IrV7mBi31h+MCGZ7tEhPPL+Dn763k4C/IWJfePwcwXtj2/oy49v6Ot+jVE9o5gzoZgnFuzhobe38e3U7jz3zWGAc3ZPlc3BrKu789WBUzzy/k73867tF8dz3xjGp7ty+d0S57eMGwc6P+DGpsTQOTiAqFALD7k+/IE6YV9j8sB4XluTRWlFNR9tyybAT3jje1dzzmpn4v+tYvGuXB6+vk+d5zgcBqvdQXCgP8YYfrVwDzuOlwCQkV9O3/hwwDk77JH3d5BXWkleaSW7skuJCw/i+OkKfnPbIOatOcyqRgL/4Mly7v7HJorOWhmWFMGciSlMd3U+AD7dnceK9HyenDaQ6FALP/9oF9uPl7DzRAkVVjsvzhrh6ulvpEd0CP3iw7hzZBI3DuzC8v353Do0gZiwICb0iWXJnjxuHZrAA2+mkRjZiTkTkxv8O/CER68mItHAB0Av4CjwLWNM8QVlRgCvAJ0BO/A7Y8wHntTrrbYePU3puWremTOGLuFBTPnLGlYfLODuMT3cZartDg7klRMU6Icx5qJ6AM8s3s/B/HKe++IAs0b34LGb+7PtWDFnqmzcMCCeE6crWLovv8EPmaIzVTz7RTqxYRZe+zqLtzYeo1OgP9+fkFyvnhkjEnly4V7255UxKKEzC3ZkMzY5hqSo+j20aUO7sujh8fSMCSEyxHK+rdMHk3mqnK1Hi7l3bE/3t5k37r+aTVlF3D48kV8t3MOSPSd56vbBrM0oQAQeu6k/BeVVLN+fz7iUGMb1jmlwX9w6LIGnP92HMfDy3VcRHOjf4v3YmGHdItmVXcLqgwX4iXPI6rU1WRSUV2Hx92PB9hy+MSqpyZ6qiFz0mzw40J8/3DWUxz7axQ+v78N3x/Rw/138475UZry8nlPlVUzo0/C+qDGyRxSf/mQCz3y6j7c3HefBa1NIiQtj1cFTdAr05+npg3l6+mCyCs5idxj8/YSBCeGICA9MSqFbVCcO5JWR7Pq/sgT48c/7ryYq1NLs/p08KJ6/rz7M8vR8FmzP4foBXYgNCwKcH0aLd54P/E935fLeluPsySnlnNXOTYPjSYzoxMIdOXx/fDJvbz7GmxuP8ts7hgLw8leZrM0o5FfTBvD88kN8lHaCkT2iALimdwwZ+eV8vjuParuDQP/z3+wOnCzj7n9sJtBfeGLqAD7als1P39tBbJiFa3rHYozhhRWHGJTQme9PSKbCaiNooR+f7MhhbUYBo3pGMWNEN67r14W3Nx9jf14Zu7NLePjd7aTEhXKmysatwxIAmDo0gVUf7+Y7/9hEdKiFt34wptXDHjzv4T8OrDTGPCsij7vu//cFZSqA+4wxGSKSCGwTkaXGmBIP6/Y6O0+UEOAnjOoZRVCAH90iO7Hq4Kk6gX+44AxWuwOr3UFeaWW9YG5MSYWVg/nlfHNUEja7g3+uP8L248Ukx4ZiCfBjfJ8YjhY6X2vzkSLuHJnE7uwSEiM7ERsWxHNfHqDCamfBj65hd3Ypv1q4hzkTUogOtdSra9qQBJ5atI/Fu3KprHZwrKiiXu+shogwvHtkve2WAD9e+e4o/rnuCA9MTHFv7xsf7u653TYskSV7TrI5q4h1GYUM6xZBVKiFX986kKIzVTwxbUCj+yM8OJAXZ40kolMgfbqEtWgfNmdItwg+35PHp7tyGdE9kmlDE3htTRYbDhdSfNZKlc3BPbX+L1vT+D6xbHjixnrbEyI6MX92Ks99ecDd825KoL8fP76+L+9sPs4nO3J4dEo/Vh8s4JreMe7QHpTYucHnThuawLShCXW2pV4wjNGYEUmRxIZZ+NPSgxSeqWJmrWHFGSMS+Z9F+0jPKyPQ34//+nAnSVEhTB+eSKC/H5/szKGkoprJA+P59a0DKausZsH2HH55ywA2ZBbxwspD3DmyGw9MTCE9r5zFu3Ipqagm2jXEdV3/Lry/9QRpR4sZ3j2C5fvzWbY/n1UHTtE5OJD35o4lOTaU2df0YtwfVvLmhqNc0zuWjYeLyCo4y59nDsffTwgPDmTyoHje23Icm8Pw6JR+AESEBLr//u0Ow7ubj/HHpQeJCw/iGleH5KZB8fzKz/lh/86cMXSNCG7RfrtYngb+DOA61+03gdVcEPjGmEO1bueKyCkgDtDAv8DOEyUMSAh3v7GuHxDHgu05VNnsBAU4t6XnlbnLH8wvb3Hgpx11fvH65qgkxqbEcPPgrvzsg53sOF7Ctf3iCLEEMKBrOBGdAtl0+DRnKm38ZtE+LAF+TBkYz+d78nhwUgp9uoTTp0s4twzpSqdGem1RoRYm9o3l0525lFfaCA70Y2qtMeGWig0L4pe3NB7a1/fvQojFn3e3HGfHiRIeutb5wdAzJpQFPxrf7OvfPPji29SUmgO3RwrPcteUfgzpFkHn4AA2ZBax40Qxw5Mi3GP3l9OwpEjemTO2xeW7RgQzoU8sC3fmMGNkN46fruCBifW/ybUmPz/hxgHxfJB2gtgwC9cP6OJ+7NahCTzz6X4+2ZnDnuxSOgX689FD49zfAB6fOoCNWUWMSY7Gz0+YPa4XH2/L5unF+/h8t3Nc/Pd3DkVEmJmaxMIdOXy+J49pQ7vi5ydM6BtLoL/wv5/tJ7u4gvJKG7FhQcwYkciPruvj/kYWHOjPrNE9eO3rw+SUnOOdzceJ6BTo7qUDzBieyOe784gLD2LqkLoffuAczrp3XC9uH55IZbWDANc3isgQZ68+KapTs8cqPNrPHj4/3hiT57p9EmiyCyEiowELcLiJMnNFJE1E0goKCjxs3pXD7jDszi5lRK3e7vX9u1BhtbP1yPlRsvS8cgJcY6CHTpYDzgNHb208Sl5p42dPbj16Gou/n/v1pw5N4N0HxtIzJoRZVzvHLv38hNHJ0Xy6O5ffLNrHDQO68K3UJFYeyCchIpif3Hh+zDfEEtDkcNL0EYnkllby4dYT3DSoK+HBgY2WvVSdLP7cODCez3bnYXcYJvZt8LrNl82Qbud7vtf174K/nzA2JYZFu3I4lH+G74xum959W7hzZDdOnD7Hn5cdBJy/T1urObh9x4hudYZWYsKCmNQ3ljfWH2XD4SIeu2WAO+zBGcTOD39n/3VoUgQje0SyYHsOCRHBzL8vlU4WZ+fEObTo7CSNS3H2rsOCApjYN46M/HJnb3/uWLb86kb+cNeweuH73bHO41B/WX6IpftOMnNUUp3hqmv7x9E9uhMPTkqpd+C/tsgQS71e/LjeMW0a9tCCHr6IrAAa6go9WfuOMcaISKMTSUUkAXgLmG2MafQMGmPMPGAeQGpqavudgneZZRWc4UyVjRHdo9zbxvWOwRLgx6qDp5jQNxZw9vD7dw2n8EwVB/Odgb8vt4zfLNrHR9uy+eihce5vA7VtOXqaYUkRdf44R/WM4uvHrq9TbmxKDMv353PToHhevvsqLAF+PHbTAOzGNHjQsjFTBnUlKGAPVTYHd13V7aL2xcW4bVgCn+7KJcTiz1U9opp/QhuqOXB7zmpnsGvYY3yfWJbtzycsKMA90+hKcPPgrnQK3MuSPSfpHRfa5kEEzgPAD1/fm9muqai13TGyG6sOFjAsKYK7W/DB+ejkfvxp2UFemjWSmFofDn5+wrdSu/P88kNc0yfWvf2v3xmJ1eZwz0BrTLfITkwZFO8+U/nuC4boggL8WfvLG5ptX3tp9h1sjJnc2GMiki8iCcaYPFegn2qkXGfgc+BJY8ymS26tF9txwjnCNaL7+a/8IZYAxqbEsOrgKX5z2yDA2cO/rn8cp8qrOOQK/HWZzumIu7NL+cOSAzw9fXCd1z5ntbMnu5QHJqXQnHvG9CAqJJDbhiW6eygRIRffOw8LCmDqkK5sPnKaCbXeWK3t2n5xhAcFMDo5uske1eXy0xv6YsA9G2a863e/Y2RimxyEayuhQQHcMqQrC3fkXJbePTiP2zx2c8NDeDcN6sqdI7vx4LUpDc7yudCkfnFM6tfwN74Hr01hTHI0vePOH7sJDQogNKjB4vXMHteLpfvyGd8nhpS41jn+c7l4+he4GJgNPOv6d9GFBUTEAiwE/m2M+djD+rzWzhMlhAcHkBJb9w9o8sAu/M+ifezPLSMuPIjCM1UMTOhMVMg5/r3Reabg+sxC+sWHMb6P82vv8O4R3DGim3vIZceJYmwOw+gWHEALDvTnrqsan4d/MX5351DOVdvd45RtITjQn3ceGNPgweP2cOHUvj5dwnjh2yOY2LftPvTayrdSu7NwR06rH+u4FJ0s/vzFdYKWp4IC/BmT0vSMpaaM6x3DD6/rzS0dYL9cLE/fic8CU0QkA5jsuo+IpIrIfFeZbwGTgPtFZKfrp3X+57zIzuMlDE+KdPcMa0wf7uxpv7vlmPuA7cCEcPrFh1Nlc3Aov5wtR04zoU8cT0wdyIjukTz6wS6+8coG9xm0W48UIwJX9by8Qx6hQQF1xlrbyrCkyAanfHYUd4zsVmdY4UoxrncMW5+czOjkls208RUiwn/fMqDB2WUdnUc9fGNMEVBvLpgxJg2Y47r9NvC2J/V4u3NWOwfzy/lhrZNTakSGWLhtaAKf7MglxvWdc1BCZ/d4+jubj1Flc55sYwnw4/25Y/ko7QSvfp3F/W9s5ebB8Zwsq2JA1851TpBSqiXiwq+8DyrVuPYf9PRSGfnlLV4MaW9uKXaHabTHcPeYHpypsvHPdUdIiAgmMsRCny5hiMB/tuUQ6C/uXlhwoD/3juvFql9cx+NTB7D6YAG7TpQwulf7HtBUSrU/DfwW+vfGoy1exGl3dglT/rKGL12LeDVn+zHntMsRjQT+qJ5R9O0SRnmVjYEJztkfIZYAekSHcK7azsgeUfUOCFoC/Hjo2t4s/dkkZl3dnXvG1l/WQCnlWzTwW8Bqc/Dbz9J5ZXWjpw/Uscx1pZ+aBbSas/5wEb3jQhv9+iwi7ulfAxPC3dv7uc44bWoWTK/YUJ79xjB3WaWU79LAb4EDJ8uw2h3sOlHSootGrHRd9GFTC5YarrLZ2XKkqNmThu66KonRvaKZXOv0+AFdXYF/Bc4AUUpdflfOxOB2VLNOdVmljaNFZ5uce5tXeo70vDK6RXbiSOFZTpZW0jUimP25ZSzamcOdV3VjQNfzZ2RuO1ZMZbXDPV+7MRGdAvnwobqrY951VRJWu4PhSVfebAGl1OWnPfwW2H2ixH2yx84TTS8B9JWrd//Yzc4lcDe5Lhrxhy/SeW1NFre8sJbvzNvkXgZhXUah6xT8i5/6lhwbyhNTB7boRBSllNLAb4Hd2aVc0zuGUIt/g4H/xvoj7kuVrTpwiu7Rnbh9eCKdgwPYlFXEkcKzrM0oZM6EZB6fOoCdJ0r4resKResyCxnZPbJN1ppRSqnadEinGRVWGxmnyrl5SFeq7Y56gf+fbdk88+l+ROC3dwxhXWYh307tjr+fMDo5ho1ZRYQHBxDgJ8ydlEKXzsFUWO28tDKDmaNOsSenlEdqLUqmlFJtRXv4zdibU4bDwPCkCEZ0jyI9r8x9ke5D+eX8+pO9jEmOZkKfWJ5cuJfKaod7addxvWM4VlTBu5uPc/PgrnTp7Fwdb+6kFGLDLPz0vR0YwxV52r1S6sqjgd+M3dnOHv2wpEhGdI+k2m7Yn1fGmSobP3x7G2HBAfz17pH8475UJvWLIzYsiLGudTpqxuXPWu3uZVXBubDYIzf2pazSRnhQgB50VUpdFjqk04xd2aUkRgQTFx7EyB7OYN5+rJi/r8rkaFEFb/9gDF3CnT33N793NRVWu3sJ4oGu5QziwoPqHZSdNboH/954jIEJndt0cTGllKqhgd+M3dklDHP1wOM7B5MQEcwLKzI4U2Xjf2cMrnPN1AuvR+rnJ7w4awTRoZZ6FwsJ9Pdj0Y/H6wwbpdRlo13LJpRUWDlWVMGwWmvUj+geyZkqG3eP6cG9LViu4Lr+XdwfGBcKsQQ0eLESpZRqC9rDb0LNmbIja12F6u4xPYgOtfDU7YObvMSfUkp1NBr4Tfhibx5RIYFcXWulyYl949r92qlKKXUpPB7SEZFoEVkuIhmufxtdh1dEOotItoi87Gm9ba2y2s7K9FPcPLirHlRVSnmF1kiyx4GVxpi+wErX/cb8P2BNK9TZ5tZmFHKmysbUoQnt3RSllGoVrRH4M4A3XbffBO5oqJCIjALigWWtUGebW7Inj8iQQK7pfenXvlRKqY6kNQI/3hiT57p9Emeo1yEifsCfgV8092IiMldE0kQkraCgZevJt7Yqm50V+/O5aVA8gTqco5TyEi06aCsiK4CGLtH+ZO07xhgjIg0tGP8jYIkxJru5mS3GmHnAPIDU1NSWXSOwla3LKKRch3OUUl6mRYFvjJnc2GMiki8iCcaYPBFJAE41UGwcMFFEfgSEARYROWOMaWq8v90s3XeS8OAAxvfWNW6UUt6jNaZlLgZmA8+6/l10YQFjzD01t0XkfiC1o4a9MYavDxUwqW8clgAdzlFKeY/WSLRngSkikgFMdt1HRFJFZH4rvP5ldTC/nPyyKq7tp3PtlVLexeMevjGmCLixge1pwJwGtv8L+Jen9baVNYecB4onaeArpbyMjllc4OtDBQzoGk7XiOD2bopSSrUqDfxazlbZ2HqkWIdzlFJeSQO/lk1ZRVjtDh3OUUp5JQ38Wr4+VECnQH9SezW6HJBSSl2xNPBr+fpQAeN6x+ga9Uopr6SB73LidAXHiir0guJKKa+lge+y4XAhABP6aOArpbyTzwW+3WFwOOov0bMus4gu4UH06RLWDq1SSqm253OBf8sLa3jl68N1tjkchg2ZhYzvE6uXLVRKeS2fCnxjDEcKz7rPpq1xML+corNWXfteKeXVfCrwrXYHNodhf25ZnWGd9ZnO8fvxOn6vlPJiPhX4Z6vsAJRX2Th2usK9fX1mISmxoSRGdmqvpimlVJvzscC3uW/vySkFwGpzsPnIae3dK6W8nm8FvvV84O91Bf7248VUWO2M76Pj90op7+Zbge8a0oHzgf/57jyCA/2Y2FfXz1FKeTePAl9EokVkuYhkuP5tcBEaEekhIstEJF1E9otIL0/qvVQVrh5+v/gw9uaUUm13sGRPHjcOiD+lyz4AABJMSURBVCc0qDUu/qWUUh2Xpz38x4GVxpi+wErX/Yb8G/ijMWYgMJqGr3vb5mrG8Mckx1BWaePDtBMUnbVy+3C9WLlSyvt5GvgzgDddt98E7riwgIgMAgKMMcsBjDFnjDEVF5a7HGqGdMakRAPwwooMwoICuK5/l/ZojlJKXVaeBn68MSbPdfskEN9AmX5AiYgsEJEdIvJHEWl0OUoRmSsiaSKSVlBQ0FixS1Jz0HZkjygC/YWC8ipuGhRPcKCujqmU8n7NBr6IrBCRvQ38zKhdzhhjgPqL1DivmzsR+AVwNZAC3N9YfcaYecaYVGNMalxc6x5IrenhR4dY6BcfDsDtwxNbtQ6llOqomj1SaYyZ3NhjIpIvIgnGmDwRSaDhsflsYKcxJsv1nE+AscDrl9jmS3a2yoafQHCgH6k9o8gvq9L590opn+HpkM5iYLbr9mxgUQNltgKRIlLTXb8B2O9hvZfkrNVGqCUAEeG/pw5gySMTsAT41MxUpZQP8zTtngWmiEgGMNl1HxFJFZH5AMYYO87hnJUisgcQ4B8e1ntJzlbZCAlyjteHWALoEh7cHs1QSql24dHkc2NMEXBjA9vTgDm17i8HhnlSV2s4a7XrfHullM/yqfGMiirnkI5SSvkinwr8s1V2Qiw6BVMp5Zt8K/CtNsJ0SEcp5aN8K/CrbIRo4CulfJRvBb7VTliQDukopXyTbwV+lY0QPWirlPJRPhP4DoehQqdlKqV8mM8E/rlq5zo6oTpLRynlo3wm8GvWwtcevlLKV/lO4FtdPXw9aKuU8lG+E/iuHr4etFVK+SqfC3w98Uop5at8J/CtNT18HdJRSvkm3wl819WutIevlPJVPhT4rh6+Br5Sykd5HPgiEi0iy0Ukw/VvVCPl/k9E9olIuoi8JCLiad0Xo2aWTpgetFVK+ajW6OE/Dqw0xvQFVrru1yEi1wDjcV4EZQjOi5lf2wp1t1iFu4evY/hKKd/UGoE/A3jTdftN4I4GyhggGLAAQUAgkN8KdbfYGasNS4Afgf4+M4qllFJ1tEb6xRtj8ly3TwLxFxYwxmwEVgF5rp+lxpj0hl5MROaKSJqIpBUUFLRC85wqquy6rIJSyqe1aEBbRFYAXRt46Mnad4wxRkRMA8/vAwwEklyblovIRGPM2gvLGmPmAfMAUlNT673WpdKVMpVSvq5FCWiMmdzYYyKSLyIJxpg8EUkATjVQ7E5gkzHmjOs5XwDjgHqB31b0aldKKV/XGkM6i4HZrtuzgUUNlDkOXCsiASISiPOAbYNDOm3lbJVdD9gqpXxaawT+s8AUEckAJrvuIyKpIjLfVeZj4DCwB9gF7DLGfNoKdbeY9vCVUr7O4wQ0xhQBNzawPQ2Y47ptBx70tC5PVFTZ6RIe1J5NUEqpduUzcxTPVNl0LXyllE/zmcCvsNoI1Vk6Sikf5jOBf7ZKr2erlPJtPhH4VpsDq92hJ14ppXyaTwR+hVVXylRKKZ8IfPdKmToPXynlw3wj8PV6tkop5VuBrydeKaV8mU8EfnmlXs9WKaV8IvD355UB0KdLWDu3RCml2o9PBH7a0dOkxIYSE6ZLKyilfJfXB77DYdh2rJjUXg1ealcppXyG1wd+VuEZiiuqSe0Z3d5NUUqpduX1gb/1aDGA9vCVUj7P6wM/7WgxMaEWkmND27spSinVrrw/8I+dZlTPKESkvZuilFLtyqPAF5GZIrJPRBwiktpEuVtE5KCIZIrI457UeTFOlVdyrKhCh3OUUgrPe/h7gbuANY0VEBF/4G/AVGAQ8B0RGeRhvS2yzT1+rwdslVLKo7UGjDHpQHPDJaOBTGNMlqvs+8AMYL8ndbfEtmPFBAX4MSQxoq2rUkqpDu9yjOF3A07Uup/t2tYgEZkrImkiklZQUOBRxUVnrXTpHIQlwOsPVSilVLOa7eGLyAqgawMPPWmMWdTaDTLGzAPmAaSmphpPXstqcxDor2GvlFLQgsA3xkz2sI4coHut+0mubW2uyubAooGvlFLA5RnS2Qr0FZFkEbEAs4DFl6Fequ0OgnQ4RymlAM+nZd4pItnAOOBzEVnq2p4oIksAjDE24MfAUiAd+NAYs8+zZreMDukopdR5ns7SWQgsbGB7LjCt1v0lwBJP6roU1XaHHrBVSikXr05Dqwa+Ukq5eXUa6pCOUkqd59VpqD18pZQ6z6vT0GpzEKQ9fKWUAnwg8HVIRymlnLw6DXWWjlJKnefVaWi1aeArpVQNr05Dq12HdJRSqobXpqExhmq70R6+Ukq5eG0aWu0OAF1LRymlXLw2Da02Z+AH+uu1bJVSCrw48KvtzqX0dXlkpZRy8to0rOnhWwL827klSinVMXh94OuQjlJKOXlv4Ntrevhe+ysqpdRF8fQCKDNFZJ+IOEQktZEy3UVklYjsd5V9xJM6W6qmh6+zdJRSysnTNNwL3AWsaaKMDfi5MWYQMBZ4WEQGeVhvs2p6+HrilVJKOXl6xat0AJHGx8mNMXlAnut2uYikA92A/Z7U3ZxqHdJRSqk6LmsaikgvYCSwuYkyc0UkTUTSCgoKLrku9ywd7eErpRTQgh6+iKwAujbw0JPGmEUtrUhEwoD/AD8zxpQ1Vs4YMw+YB5Cammpa+voXcs/S0R6+UkoBLQh8Y8xkTysRkUCcYf+OMWaBp6/XEu5ZOtrDV0op4DIM6YhzgP91IN0Y83xb11dDZ+kopVRdnk7LvFNEsoFxwOcistS1PVFElriKjQfuBW4QkZ2un2ketboFqnWWjlJK1eHpLJ2FwMIGtucC01y31wGX/XTX80sraOArpRT4wJm22sNXSiknr01D7eErpVRdXpuGegEUpZSqy2vT8PxqmV77Kyql1EXx2jSstjvw9xP8/XR5ZKWUAi8OfKvNoSddKaVULV6biFabQy9+opRStXhv4NuNXt5QKaVq8d7Atzl0ho5SStXitYloteuQjlJK1ea1gV9tc+hJV0opVYvXJqLVroGvlFK1eW0iOmfpeO2vp5RSF81rE9Fq13n4SilVm9cmolXH8JVSqg5PL4AyU0T2iYhDRFKbKesvIjtE5DNP6mwpPdNWKaXq8jQR9wJ3AWtaUPYRIN3D+lqsWg/aKqVUHR4lojEm3RhzsLlyIpIE3ArM96S+i6GzdJRSqq7LlYgvAL8EHM0VFJG5IpImImkFBQWXXGG1ztJRSqk6mk1EEVkhInsb+JnRkgpE5DbglDFmW0vKG2PmGWNSjTGpcXFxLXlKg7SHr5RSdTV7EXNjzGQP6xgPTBeRaUAw0FlE3jbGfNfD121SlR60VUqpOto8EY0xTxhjkowxvYBZwFdtHfagB22VUupCnk7LvFNEsoFxwOcistS1PVFElrRGAy+VTstUSqm6mh3SaYoxZiGwsIHtucC0BravBlZ7UmdL2OwOHAbt4SulVC1emYjVdgPoBcyVUqo2r0xEq805+1N7+EopdZ5XJmKV3Q5o4CulVG1emYg1QzoWveKVUkq5eWXg65COUkrV55WJ6A58f/92bolSSnUcXhn41XZn4OtFzJVS6jyvDPwqHdJRSql6vDIRdQxfKaXq88pErBnS0aUVlFLqPK9MRO3hK6VUfV6ZiFb3QVuv/PWUUuqSeGUiuod0tIevlFJuXpmI7lk62sNXSik3r0xEHcNXSqn6PL0AykwR2SciDhFJbaJcpIh8LCIHRCRdRMZ5Um9zdJaOUkrV52ki7gXuAtY0U+5F4EtjzABgOJDuYb1N0h6+UkrV5+kVr9IBRBpfwkBEIoBJwP2u51gBqyf1NqdaZ+kopVQ9lyMRk4EC4A0R2SEi80UktC0rrOnh61o6Sil1XrOBLyIrRGRvAz8zWlhHAHAV8IoxZiRwFni8ifrmikiaiKQVFBS0sIq6quwOLAF+TX7zUEopX9PskI4xZrKHdWQD2caYza77H9NE4Btj5gHzAFJTU82lVFhtM3rAVimlLtDmqWiMOQmcEJH+rk03Avvbsk6r3a4HbJVS6gKeTsu8U0SygXHA5yKy1LU9UUSW1Cr6E+AdEdkNjAB+70m9zbHaHNrDV0qpC3g6S2chsLCB7bnAtFr3dwKNztNvbdV2Q2CAjt8rpVRtXtkN1h6+UkrV55WpWGVzYAnQ69kqpVRtXhn41XYHFp2Dr5RSdXhl4FttDp2lo5RSF/DKVLTaNfCVUupCXpmK1XaHrqOjlFIX8MpU1Fk6SilVn1emoo7hK6VUfV6Zila79vCVUupCXpmK2sNXSqn6vDIVdZaOUkrV55WpWG3TWTpKKXUhr0zFKYPiGZzYub2boZRSHYpHq2V2VC/MGtneTVBKqQ7HK3v4Siml6tPAV0opH+HpFa9misg+EXGISKMXOBGRR13l9orIeyIS7Em9SimlLp6nPfy9wF3AmsYKiEg34KdAqjFmCOAPzPKwXqWUUhfJ00scpgOINLv2fADQSUSqgRAg15N6lVJKXbw2H8M3xuQAfwKOA3lAqTFmWWPlRWSuiKSJSFpBQUFbN08ppXxGs4EvIitcY+8X/sxoSQUiEgXMAJKBRCBURL7bWHljzDxjTKoxJjUuLq6lv4dSSqlmNDukY4yZ7GEdk4EjxpgCABFZAFwDvO3h6yqllLoIl+PEq+PAWBEJAc4BNwJpLXnitm3bCkXk2CXWGwsUXuJz29uV2vYrtd2gbW8v2vbW17OxB8QYc8mvKiJ3An8F4oASYKcx5mYRSQTmG2Omuco9A3wbsAE7gDnGmKpLrrhlbUszxjQ6VbQju1LbfqW2G7Tt7UXbfnl5OktnIbCwge25wLRa958CnvKkLqWUUp7RM22VUspHeHPgz2vvBnjgSm37ldpu0La3F237ZeTRGL5SSqkrhzf38JVSStWiga+UUj7C6wJfRG4RkYMikikij7d3e5oiIt1FZJWI7HetJvqIa3u0iCwXkQzXv1Ht3dbGiIi/iOwQkc9c95NFZLNr/38gIpb2bmNDRCRSRD4WkQMiki4i466E/d7QyrMdeZ+LyD9F5JSI7K21rcH9LE4vuX6P3SJyVQdr9x9dfy+7RWShiETWeuwJV7sPisjN7dPq5nlV4IuIP/A3YCowCPiOiAxq31Y1yQb83BgzCBgLPOxq7+PASmNMX2Cl635H9QiQXuv+c8BfjDF9gGLgB+3Squa9CHxpjBkADMf5O3To/d7EyrMdeZ//C7jlgm2N7eepQF/Xz1zglcvUxob8i/rtXg4MMcYMAw4BTwC43rOzgMGu5/zdlUUdjlcFPjAayDTGZBljrMD7ONfx6ZCMMXnGmO2u2+U4Q6cbzja/6Sr2JnBH+7SwaSKSBNwKzHfdF+AG4GNXkQ7ZdhGJACYBrwMYY6zGmBKujP1es/JsAM6VZ/PowPvcGLMGOH3B5sb28wzg38ZpExApIgmXp6V1NdRuY8wyY4zNdXcTkOS6PQN43xhTZYw5AmTizKIOx9sCvxtwotb9bNe2Dk9EegEjgc1AvDEmz/XQSSC+nZrVnBeAXwIO1/0YoKTWm6Kj7v9koAB4wzUcNV9EQung+72hlWeBbVwZ+7y2xvbzlfT+/T7whev2FdNubwv8K5KIhAH/AX5mjCmr/ZhxzpvtcHNnReQ24JQxZlt7t+USBABXAa8YY0YCZ7lg+KYj7veGVp6l/rDDFaUj7ufmiMiTOIdj32nvtlwsbwv8HKB7rftJrm0dlogE4gz7d4wxC1yb82u+yrr+PdVe7WvCeGC6iBzFOXR2A85x8UjXcAN03P2fDWQbYza77n+M8wOgo+9398qzxphqYAHO/4crYZ/X1th+7vDvXxG5H7gNuMecP4mpw7e7hrcF/lagr2vWggXngZTF7dymRrnGvF8H0o0xz9d6aDEw23V7NrDocretOcaYJ4wxScaYXjj381fGmHuAVcA3XcU6attPAidEpL9r043Afjr+fnevPOv626lpd4ff5xdobD8vBu5zzdYZi/NiSXkNvUB7EJFbcA5hTjfGVNR6aDEwS0SCRCQZ50HnLe3RxmYZY7zqB+eibYeAw8CT7d2eZto6AefX2d3ATtfPNJxj4SuBDGAFEN3ebW3m97gO+Mx1OwXnH3sm8BEQ1N7ta6TNI3Au070b+ASIuhL2O/AMcADn9aTfAoI68j4H3sN5vKEa5zerHzS2nwHBOcvuMLAH52ykjtTuTJxj9TXv1VdrlX/S1e6DwNT23u+N/ejSCkop5SO8bUhHKaVUIzTwlVLKR2jgK6WUj9DAV0opH6GBr5RSPkIDXymlfIQGvlJK+Yj/D25TcikpO0ZPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(len(loss_save)), loss_save)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}