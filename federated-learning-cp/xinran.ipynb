{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def args_parser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # federated arguments\n",
    "    parser.add_argument('--epochs', type=int, default=10, help=\"rounds of training\")\n",
    "    parser.add_argument('--num_users', type=int, default=100, help=\"number of users: K\")\n",
    "    parser.add_argument('--frac', type=float, default=0.1, help=\"the fraction of clients: C\")\n",
    "    parser.add_argument('--local_ep', type=int, default=5, help=\"the number of local epochs: E\")\n",
    "    parser.add_argument('--local_bs', type=int, default=10, help=\"local batch size: B\")\n",
    "    parser.add_argument('--bs', type=int, default=128, help=\"test batch size\")\n",
    "    parser.add_argument('--lr', type=float, default=0.01, help=\"learning rate\")\n",
    "    parser.add_argument('--momentum', type=float, default=0.5, help=\"SGD momentum (default: 0.5)\")\n",
    "    parser.add_argument('--split', type=str, default='user', help=\"train-test split type, user or sample\")\n",
    "\n",
    "    # model arguments\n",
    "    parser.add_argument('--model', type=str, default='mlp', help='model name')\n",
    "    parser.add_argument('--kernel_num', type=int, default=9, help='number of each kind of kernel')\n",
    "    parser.add_argument('--kernel_sizes', type=str, default='3,4,5',\n",
    "                        help='comma-separated kernel size to use for convolution')\n",
    "    parser.add_argument('--norm', type=str, default='batch_norm', help=\"batch_norm, layer_norm, or None\")\n",
    "    parser.add_argument('--num_filters', type=int, default=32, help=\"number of filters for conv nets\")\n",
    "    parser.add_argument('--max_pool', type=str, default='True',\n",
    "                        help=\"Whether use max pooling rather than strided convolutions\")\n",
    "\n",
    "    # other arguments\n",
    "    parser.add_argument('--dataset', type=str, default='mnist', help=\"name of dataset\")\n",
    "    parser.add_argument('--iid', action='store_true', help='whether i.i.d or not')\n",
    "    parser.add_argument('--num_classes', type=int, default=10, help=\"number of classes\")\n",
    "    parser.add_argument('--num_channels', type=int, default=3, help=\"number of channels of imges\")\n",
    "    parser.add_argument('--gpu', type=int, default=0, help=\"GPU ID, -1 for CPU\")\n",
    "    parser.add_argument('--stopping_rounds', type=int, default=10, help='rounds of early stopping')\n",
    "    parser.add_argument('--verbose', action='store_true', help='verbose print')\n",
    "    parser.add_argument('--seed', type=int, default=1, help='random seed (default: 1)')\n",
    "    parser.add_argument('--all_clients', action='store_true', help='aggregation over all clients')\n",
    "    args = parser.parse_args(args=[])\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Python version: 3.6\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "from utils.sampling import mnist_iid, mnist_noniid, cifar_iid\n",
    "# from utils.options import args_parser\n",
    "from models.Update import LocalUpdate\n",
    "from models.Nets import MLP, CNNMnist, CNNCifar\n",
    "from models.Fed import FedAvg\n",
    "from models.test import test_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse args\n",
    "args = args_parser()\n",
    "args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(all_clients=False, bs=128, dataset='mnist', device=device(type='cuda', index=0), epochs=10, frac=0.1, gpu=0, iid=False, kernel_num=9, kernel_sizes='3,4,5', local_bs=10, local_ep=5, lr=0.01, max_pool='True', model='mlp', momentum=0.5, norm='batch_norm', num_channels=3, num_classes=10, num_filters=32, num_users=100, seed=1, split='user', stopping_rounds=10, verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:45: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (layer_input): Linear(in_features=784, out_features=200, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (layer_hidden): Linear(in_features=200, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# load dataset and split users\n",
    "if args.dataset == 'mnist':\n",
    "    trans_mnist = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.repeat(1,1,1))])\n",
    "    dataset_train = datasets.MNIST('./data/mnist/', train=True, download=False, transform=trans_mnist)\n",
    "    dataset_test = datasets.MNIST('./data/mnist/', train=False, download=True, transform=trans_mnist)\n",
    "    # sample users\n",
    "    if args.iid:\n",
    "        dict_users = mnist_iid(dataset_train, args.num_users)\n",
    "    else:\n",
    "        dict_users = mnist_noniid(dataset_train, args.num_users)\n",
    "elif args.dataset == 'cifar':\n",
    "    trans_cifar = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    dataset_train = datasets.CIFAR10('./data/cifar', train=True, download=True, transform=trans_cifar)\n",
    "    dataset_test = datasets.CIFAR10('./data/cifar', train=False, download=True, transform=trans_cifar)\n",
    "    if args.iid:\n",
    "        dict_users = cifar_iid(dataset_train, args.num_users)\n",
    "    else:\n",
    "        exit('Error: only consider IID setting in CIFAR10')\n",
    "else:\n",
    "    exit('Error: unrecognized dataset')\n",
    "img_size = dataset_train[0][0].shape\n",
    "\n",
    "# build model\n",
    "if args.model == 'cnn' and args.dataset == 'cifar':\n",
    "    net_glob = CNNCifar(args=args).to(args.device)\n",
    "elif args.model == 'cnn' and args.dataset == 'mnist':\n",
    "    net_glob = CNNMnist(args=args).to(args.device)\n",
    "elif args.model == 'mlp':\n",
    "    len_in = 1\n",
    "    for x in img_size:\n",
    "        len_in *= x\n",
    "    net_glob = MLP(dim_in=len_in, dim_hidden=200, dim_out=args.num_classes).to(args.device)\n",
    "else:\n",
    "    exit('Error: unrecognized model')\n",
    "print(net_glob)\n",
    "net_glob.train()\n",
    "\n",
    "# copy weights\n",
    "w_glob = net_glob.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer_input.weight',\n",
       "              tensor([[-0.0065,  0.0075, -0.0139,  ..., -0.0131, -0.0013,  0.0232],\n",
       "                      [ 0.0010, -0.0265, -0.0055,  ..., -0.0292,  0.0039, -0.0034],\n",
       "                      [-0.0303,  0.0322, -0.0353,  ..., -0.0059,  0.0017,  0.0335],\n",
       "                      ...,\n",
       "                      [ 0.0313,  0.0068, -0.0206,  ...,  0.0311, -0.0022, -0.0132],\n",
       "                      [-0.0349,  0.0134,  0.0289,  ...,  0.0018,  0.0069,  0.0258],\n",
       "                      [ 0.0116, -0.0150, -0.0152,  ..., -0.0146, -0.0016, -0.0069]],\n",
       "                     device='cuda:0')),\n",
       "             ('layer_input.bias',\n",
       "              tensor([ 2.3478e-02, -3.2985e-02,  2.7407e-02,  3.2489e-02, -1.0937e-02,\n",
       "                       2.7319e-02,  1.2831e-02,  2.9404e-02, -2.8741e-02, -3.1809e-02,\n",
       "                       1.0833e-03,  7.0328e-03,  2.8064e-03,  4.9374e-03,  1.0865e-02,\n",
       "                       3.4924e-02,  1.0170e-06, -1.5710e-02, -3.3714e-02, -3.2777e-02,\n",
       "                      -1.0485e-02, -8.1401e-03,  2.5854e-02,  5.1448e-03, -2.2042e-02,\n",
       "                       3.0822e-02, -3.4303e-02,  9.7833e-03, -2.1853e-02, -2.9121e-02,\n",
       "                      -1.1684e-02,  2.5365e-02,  2.1809e-02, -9.7708e-03,  1.2043e-02,\n",
       "                       3.4631e-02,  2.2165e-02, -2.6881e-02, -2.7873e-02,  2.4906e-02,\n",
       "                      -8.5524e-03,  6.7032e-03, -1.9524e-03,  2.4659e-02, -2.7318e-03,\n",
       "                       3.2400e-02, -3.0276e-02,  2.2483e-02,  3.1408e-02,  3.3542e-02,\n",
       "                       2.4525e-02, -3.2374e-02, -3.1885e-02,  3.3339e-02,  9.0415e-03,\n",
       "                      -2.6649e-02, -3.0818e-02, -1.6950e-03, -3.4359e-02, -4.5473e-03,\n",
       "                       2.6863e-02,  3.8407e-03,  2.9052e-02, -1.8774e-02, -2.4501e-03,\n",
       "                      -3.1478e-02,  3.8867e-03, -2.0560e-02, -3.0029e-02,  2.2781e-02,\n",
       "                      -1.1211e-02,  1.4482e-02, -8.7590e-03, -3.3208e-02,  1.2947e-02,\n",
       "                      -3.1674e-02, -1.2655e-02, -7.9852e-03,  3.4503e-02, -1.0647e-02,\n",
       "                       1.5864e-02, -2.8001e-02, -2.8663e-02,  8.8721e-03,  1.3252e-02,\n",
       "                       2.8697e-02,  2.8415e-02,  1.7611e-02, -1.7484e-02, -3.0667e-02,\n",
       "                       1.1144e-02, -3.2442e-02,  2.2165e-03,  2.8507e-02,  1.4518e-02,\n",
       "                      -3.4099e-02, -2.8431e-02,  6.8142e-03, -2.5532e-03,  3.3918e-02,\n",
       "                       9.9205e-04, -1.0194e-02,  1.0125e-02, -2.7109e-02, -1.0691e-02,\n",
       "                       2.3635e-02,  3.3656e-02, -3.9440e-03,  3.3640e-02, -3.0245e-02,\n",
       "                      -2.0230e-02,  1.2859e-02,  3.1267e-02, -2.1596e-02, -3.4310e-02,\n",
       "                       1.9500e-03, -1.0066e-02, -2.2362e-02, -7.2045e-04,  1.5145e-02,\n",
       "                      -2.1817e-02,  3.3560e-02,  3.6383e-03, -5.9760e-03,  3.6729e-03,\n",
       "                       3.2948e-02, -1.7271e-02, -2.6133e-02,  2.5250e-02, -3.2729e-02,\n",
       "                      -1.3672e-02,  2.8359e-02,  5.5098e-03, -1.4246e-02,  1.5661e-02,\n",
       "                      -2.0016e-03, -1.1005e-02,  2.8697e-02, -2.3197e-02,  2.4175e-03,\n",
       "                      -1.1955e-03, -3.5219e-02, -2.9623e-02,  1.2012e-02,  2.6844e-02,\n",
       "                       1.9286e-02,  4.0559e-03,  4.7701e-03, -1.5584e-02,  2.3245e-02,\n",
       "                       3.2286e-02,  7.9353e-03,  2.8537e-02,  1.9173e-02, -2.1286e-02,\n",
       "                       3.5523e-02, -8.3593e-03,  6.3357e-03,  1.1740e-02, -1.4027e-02,\n",
       "                       8.3324e-03,  1.0836e-02,  3.1602e-02,  2.7184e-02,  2.2296e-02,\n",
       "                      -1.8149e-02,  1.6240e-02,  2.5437e-02,  2.0184e-02, -2.8072e-02,\n",
       "                       1.6554e-02, -1.1670e-02,  1.9836e-02,  1.4095e-02, -3.1481e-02,\n",
       "                      -2.5496e-02, -1.7016e-02, -1.9030e-02, -2.4943e-02, -1.6915e-02,\n",
       "                       3.1652e-02,  1.0683e-02,  2.9728e-02, -2.1551e-02, -2.2480e-02,\n",
       "                       9.7186e-03,  2.2443e-02, -1.6666e-02, -3.4934e-02, -3.1260e-02,\n",
       "                       3.2676e-02, -3.5451e-03, -3.1139e-02,  1.5234e-02, -2.7538e-02,\n",
       "                       6.0453e-03, -2.8754e-02,  1.0474e-02,  1.9326e-02,  1.9451e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('layer_hidden.weight',\n",
       "              tensor([[-0.0201, -0.0344,  0.0449,  ...,  0.0238,  0.0293, -0.0475],\n",
       "                      [ 0.0678, -0.0584, -0.0472,  ..., -0.0528,  0.0289, -0.0693],\n",
       "                      [ 0.0648, -0.0405,  0.0149,  ..., -0.0455,  0.0121, -0.0126],\n",
       "                      ...,\n",
       "                      [-0.0014, -0.0439,  0.0448,  ..., -0.0691, -0.0291,  0.0679],\n",
       "                      [ 0.0353,  0.0252,  0.0186,  ...,  0.0092, -0.0660,  0.0146],\n",
       "                      [-0.0480,  0.0228, -0.0187,  ...,  0.0273, -0.0689,  0.0683]],\n",
       "                     device='cuda:0')),\n",
       "             ('layer_hidden.bias',\n",
       "              tensor([-0.0476, -0.0398,  0.0676, -0.0502, -0.0404,  0.0521, -0.0078,  0.0452,\n",
       "                      -0.0617,  0.0078], device='cuda:0'))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   0, Average loss 0.301\n",
      "Round   1, Average loss 0.175\n",
      "Round   2, Average loss 0.129\n",
      "Round   3, Average loss 0.140\n",
      "Round   4, Average loss 0.143\n",
      "Round   5, Average loss 0.126\n",
      "Round   6, Average loss 0.116\n",
      "Round   7, Average loss 0.117\n",
      "Round   8, Average loss 0.087\n",
      "Round   9, Average loss 0.096\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "loss_train = []\n",
    "cv_loss, cv_acc = [], []\n",
    "val_loss_pre, counter = 0, 0\n",
    "net_best = None\n",
    "best_loss = None\n",
    "val_acc_list, net_list = [], []\n",
    "\n",
    "if args.all_clients: \n",
    "    print(\"Aggregation over all clients\")\n",
    "    w_locals = [w_glob for i in range(args.num_users)]\n",
    "for iter in range(args.epochs):\n",
    "    loss_locals = []\n",
    "    if not args.all_clients:\n",
    "        w_locals = []\n",
    "    m = max(int(args.frac * args.num_users), 1)\n",
    "    idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "    for idx in idxs_users:\n",
    "        local = LocalUpdate(args=args, dataset=dataset_train, idxs=dict_users[idx])\n",
    "        w, loss = local.train(net=copy.deepcopy(net_glob).to(args.device))\n",
    "        if args.all_clients:\n",
    "            w_locals[idx] = copy.deepcopy(w)\n",
    "        else:\n",
    "            w_locals.append(copy.deepcopy(w))\n",
    "        loss_locals.append(copy.deepcopy(loss))\n",
    "    # update global weights\n",
    "    w_glob = FedAvg(w_locals)\n",
    "\n",
    "    # copy weight to net_glob\n",
    "    net_glob.load_state_dict(w_glob)\n",
    "\n",
    "    # print loss\n",
    "    loss_avg = sum(loss_locals) / len(loss_locals)\n",
    "    print('Round {:3d}, Average loss {:.3f}'.format(iter, loss_avg))\n",
    "    loss_train.append(loss_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss curve\n",
    "plt.figure()\n",
    "plt.plot(range(len(loss_train)), loss_train)\n",
    "plt.ylabel('train_loss')\n",
    "plt.savefig('./save/fed_{}_{}_{}_C{}_iid{}.png'.format(args.dataset, args.model, args.epochs, args.frac, args.iid))\n",
    "\n",
    "# testing\n",
    "net_glob.eval()\n",
    "acc_train, loss_train = test_img(net_glob, dataset_train, args)\n",
    "acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "print(\"Training accuracy: {:.2f}\".format(acc_train))\n",
    "print(\"Testing accuracy: {:.2f}\".format(acc_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
